{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a0853c",
   "metadata": {},
   "source": [
    "# Fairness Results Visualisation Notebook\n",
    "\n",
    "This notebook loads fairness experiment results stored as JSON files and produces\n",
    "summary tables and plots. It is tailored to the JSON structure produced by your\n",
    "framework, for example:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"dataset\": \"adult\",\n",
    "  \"protected_attr\": \"gender\",\n",
    "  \"dp\": false,\n",
    "  \"model_type\": \"logreg\",\n",
    "  \"global_metrics\": {\n",
    "    \"accuracy_overall\": 0.79,\n",
    "    \"accuracy_by_group\": { ... },\n",
    "    \"ks_stat\": ...,\n",
    "    \"ks_pvalue\": ...,\n",
    "    \"welch_t_stat\": ...,\n",
    "    \"welch_t_pvalue\": ...,\n",
    "    \"tv_distance\": ...,\n",
    "    \"epsilon_empirical\": ...\n",
    "  },\n",
    "  \"groups\": [\n",
    "    {\n",
    "      \"group_id\": 0,\n",
    "      \"group_label\": \"Female\",\n",
    "      \"num_samples\": ...,\n",
    "      \"accuracy\": ...,\n",
    "      \"ks_stat\": ...,\n",
    "      \"ks_pvalue\": ...,\n",
    "      \"welch_t_stat\": ...,\n",
    "      \"welch_t_pvalue\": ...,\n",
    "      \"tv_distance\": ...,\n",
    "      \"epsilon_empirical\": ...\n",
    "    },\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "You can point it at a directory containing files like:\n",
    "\n",
    "- `fairness_adult_gender_dpFalse.json`\n",
    "- `fairness_compas_gender_dpFalse.json`\n",
    "- `fairness_compas_race_dpTrue.json`\n",
    "\n",
    "and it will aggregate and visualise the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0be5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make plots inline if you're in a Jupyter environment\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 4)\n",
    "plt.rcParams['axes.grid'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9facd20f",
   "metadata": {},
   "source": [
    "## Load and parse JSON result files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594087e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fairness_results(results_dir: str):\n",
    "    \"\"\"\n",
    "    Load all fairness_*.json files from a directory and return two DataFrames:\n",
    "\n",
    "    - global_df: one row per experiment (dataset/protected_attr/dp/model_type)\n",
    "    - groups_df: one row per group per experiment\n",
    "    \"\"\"\n",
    "    results_dir = Path(results_dir)\n",
    "    json_files = sorted(results_dir.glob(\"fairness_*.json\"))\n",
    "\n",
    "    global_rows = []\n",
    "    group_rows = []\n",
    "\n",
    "    for path in json_files:\n",
    "        with path.open(\"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        dataset = data.get(\"dataset\")\n",
    "        protected_attr = data.get(\"protected_attr\")\n",
    "        dp = bool(data.get(\"dp\"))\n",
    "        model_type = data.get(\"model_type\", \"\")\n",
    "\n",
    "        gm = data[\"global_metrics\"]\n",
    "        global_rows.append(\n",
    "            {\n",
    "                \"file\": path.name,\n",
    "                \"dataset\": dataset,\n",
    "                \"protected_attr\": protected_attr,\n",
    "                \"dp\": dp,\n",
    "                \"model_type\": model_type,\n",
    "                \"accuracy_overall\": gm[\"accuracy_overall\"],\n",
    "                \"ks_stat\": gm[\"ks_stat\"],\n",
    "                \"ks_pvalue\": gm[\"ks_pvalue\"],\n",
    "                \"welch_t_stat\": gm[\"welch_t_stat\"],\n",
    "                \"welch_t_pvalue\": gm[\"welch_t_pvalue\"],\n",
    "                \"tv_distance\": gm[\"tv_distance\"],\n",
    "                \"epsilon_empirical\": gm[\"epsilon_empirical\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        for g in data[\"groups\"]:\n",
    "            row = {\n",
    "                \"file\": path.name,\n",
    "                \"dataset\": dataset,\n",
    "                \"protected_attr\": protected_attr,\n",
    "                \"dp\": dp,\n",
    "                \"model_type\": model_type,\n",
    "                \"group_id\": g[\"group_id\"],\n",
    "                \"group_label\": g[\"group_label\"],\n",
    "                \"num_samples\": g[\"num_samples\"],\n",
    "                \"accuracy\": g[\"accuracy\"],\n",
    "                \"ks_stat\": g[\"ks_stat\"],\n",
    "                \"ks_pvalue\": g[\"ks_pvalue\"],\n",
    "                \"welch_t_stat\": g[\"welch_t_stat\"],\n",
    "                \"welch_t_pvalue\": g[\"welch_t_pvalue\"],\n",
    "                \"tv_distance\": g[\"tv_distance\"],\n",
    "                \"epsilon_empirical\": g[\"epsilon_empirical\"],\n",
    "            }\n",
    "            group_rows.append(row)\n",
    "\n",
    "    global_df = pd.DataFrame(global_rows)\n",
    "    groups_df = pd.DataFrame(group_rows)\n",
    "    return global_df, groups_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11232839",
   "metadata": {},
   "source": [
    "## Load your results\n",
    "\n",
    "Set `RESULTS_DIR` to the directory where you store your JSON files.\n",
    "For example, if your project writes them to `results/`, just leave the default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e12d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"results\"  # change this if needed\n",
    "\n",
    "global_df, groups_df = load_fairness_results(RESULTS_DIR)\n",
    "\n",
    "print(\"Global metrics:\")\n",
    "display(global_df)\n",
    "\n",
    "print(\"\\nPer-group metrics:\")\n",
    "display(groups_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5933a5ab",
   "metadata": {},
   "source": [
    "## Global comparison: accuracy and ε by dataset / attribute / DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24fc5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a convenient label for plotting\n",
    "global_df = global_df.copy()\n",
    "global_df[\"config\"] = (\n",
    "    global_df[\"dataset\"] + \"_\" +\n",
    "    global_df[\"protected_attr\"] + \"_dp\" + global_df[\"dp\"].astype(int).astype(str)\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Accuracy\n",
    "ax = axes[0]\n",
    "sorted_idx = np.argsort(global_df[\"accuracy_overall\"].values)\n",
    "ax.bar(\n",
    "    np.arange(len(global_df)),\n",
    "    global_df[\"accuracy_overall\"].values[sorted_idx]\n",
    ")\n",
    "ax.set_xticks(np.arange(len(global_df)))\n",
    "ax.set_xticklabels(global_df[\"config\"].values[sorted_idx], rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Overall accuracy by configuration\")\n",
    "\n",
    "# Epsilon\n",
    "ax = axes[1]\n",
    "sorted_idx_eps = np.argsort(global_df[\"epsilon_empirical\"].values)\n",
    "ax.bar(\n",
    "    np.arange(len(global_df)),\n",
    "    global_df[\"epsilon_empirical\"].values[sorted_idx_eps]\n",
    ")\n",
    "ax.set_xticks(np.arange(len(global_df)))\n",
    "ax.set_xticklabels(global_df[\"config\"].values[sorted_idx_eps], rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Empirical epsilon\")\n",
    "ax.set_title(\"Empirical ε by configuration\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b613e337",
   "metadata": {},
   "source": [
    "## Per-group metrics\n",
    "\n",
    "Pick a specific configuration (dataset, protected attribute, DP on/off) and\n",
    "visualise accuracy and ε per group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e49865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a configuration to inspect in detail\n",
    "CFG_DATASET = \"compas\"       # e.g. \"adult\" or \"compas\"\n",
    "CFG_PROTECTED = \"gender\"     # e.g. \"gender\" or \"race\"\n",
    "CFG_DP = False               # True or False\n",
    "\n",
    "mask = (\n",
    "    (groups_df[\"dataset\"] == CFG_DATASET)\n",
    "    & (groups_df[\"protected_attr\"] == CFG_PROTECTED)\n",
    "    & (groups_df[\"dp\"] == CFG_DP)\n",
    ")\n",
    "\n",
    "subset = groups_df[mask].copy()\n",
    "if subset.empty:\n",
    "    print(\"No groups found for this configuration.\")\n",
    "else:\n",
    "    subset = subset.sort_values(\"group_id\")\n",
    "    print(\"Groups for\", CFG_DATASET, CFG_PROTECTED, \"DP:\", CFG_DP)\n",
    "    display(subset[[\"group_id\", \"group_label\", \"num_samples\", \"accuracy\", \"epsilon_empirical\"]])\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Accuracy per group\n",
    "    ax = axes[0]\n",
    "    ax.bar(np.arange(len(subset)), subset[\"accuracy\"].values)\n",
    "    ax.set_xticks(np.arange(len(subset)))\n",
    "    ax.set_xticklabels(subset[\"group_label\"].values, rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(\"Accuracy per group\")\n",
    "\n",
    "    # epsilon per group\n",
    "    ax = axes[1]\n",
    "    ax.bar(np.arange(len(subset)), subset[\"epsilon_empirical\"].values)\n",
    "    ax.set_xticks(np.arange(len(subset)))\n",
    "    ax.set_xticklabels(subset[\"group_label\"].values, rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel(\"Empirical epsilon\")\n",
    "    ax.set_title(\"Empirical ε per group\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a8261",
   "metadata": {},
   "source": [
    "## KS p-values across configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "sorted_idx = np.argsort(global_df[\"ks_pvalue\"].values)\n",
    "ax.bar(\n",
    "    np.arange(len(global_df)),\n",
    "    global_df[\"ks_pvalue\"].values[sorted_idx]\n",
    ")\n",
    "ax.set_xticks(np.arange(len(global_df)))\n",
    "ax.set_xticklabels(global_df[\"config\"].values[sorted_idx], rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"KS p-value\")\n",
    "ax.set_title(\"KS test p-values by configuration\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
